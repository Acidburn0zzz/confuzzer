\chapter{Introduction}
Finding bugs in existing software and computer systems is difficult, and while
manually finding bugs can be effective to a limited extent, a large part of
Computer Security has moved to using automated methods for finding bugs within a
program. This paper presents \textit{Confuzzer}, a system that helps find bugs
in a specific class of closed-source binaries which other existing systems tend
to have trouble with. Many existing systems fail to perform well with programs
that have a large branching factor and depend on complex conditionals to
determine the control flow of the program, and as a result end up exploring only
a small part of the program. This can result in vulnerabilities in other parts
of the program being completely missing. While the system described is more
specialized than existing tools, the goal is to create a system that allows
security engineers to look for and attack bugs in programs that have previously
been difficult to explore using automated methods. 

Automated methods of bug finding are necessary, since even with systems like Bug
Bounties and Vulnerability Reward Programs, where bug hunting is distributed
among many security researchers with prizes of up to several tens of thousands,
the number of bugs in existing systems makes it infeasible to find all of them
and prevent attackers from exploiting them \cite{googlevrp}. This means that we
need automated methods of generating and testing inputs against our target
binary, in the hopes that one of the generated inputs will result in a bug being
discovered. This method of randomly testing inputs to cause programs to behave
incorrectly is called \textit{Fuzzing} and was invented as early as 1988 as part
of a graduate class \cite{fuzzingorigin}. Since those early days, the art of
\textit{Fuzzing} has advanced to a great degree, with advancements in how test
cases are actually generated.

\textit{Fuzzing} systems tend to be divided into 2 main categories. The first is
black-box fuzzing, where the fuzzing is performed independently of the program
that is being analyzed, and thus tends to result in random inputs being sent to
the binary, and results in many inputs that hit the same code path within the
binary. As can be imagined, black-box fuzzing is fairly inefficient and can't
completely test non-trivial binaries. The second main form of fuzzing is
white-box fuzzing, where the fuzzer has knowledge of the binary being run, and
can create test inputs based on this knowledge. If source code isn't available,
this is sometimes known as grey-box fuzzing since the feedback to the fuzzer is
from the machine code that makes up the program, rather than the original
higher-level code. The system developed for this thesis falls into the realm of
white-box/grey-box fuzzing since the inputs are very much determined by the
program execution though we don't require source code.

However, while most existing black-box fuzzing systems work off the idea of
using code coverage and input mutation to generate new test cases, the system
used in this thesis is based on \textit{Concolic Execution}. Concolic Execution
is a specific form of more general Symbolic Execution that was created as part
of the CUTE system \cite{cutesystem}. Symbolic Execution is a method of
evaluating a program, either at the higher-level source code level, or in our
case the assembly level, where each operation performed on the input data we are
testing is stored as a symbolic expression and whenever we hit some sort of
branch we store the branch as a place where different paths might be taken, and
then at the end we use all the constraints and symbolic expressions to generate
new paths through the program execution. The difference between ordinary
Symbolic Execution and Concolic Execution is how we handle branches. In Symbolic
Execution, whenever we reach a branch, we create a new thread that continues
exploring down each path in the branch, and eventually all the threads complete
and we have a massive series of constraints for all possible
executions. Meanwhile in Concolic Execution, we initially start with some
concrete values for the input and just explore down the path of execution that
those values end up taking, and then we try running the program again with new
values.

By exploring the program state and building up constraints for each possible
execution path, we can solve the constraints for different inputs that should
travel down different parts of the program, allowing us to thoroughly test
large swaths of the program with fewer inputs. By combining these two ideas
together, we hopefully will have a system that can more efficiently test closed
source programs and find vulnerabilities in them without having to wait until an
attacker starts actively exploiting the vulnerability.

Our implementation of the \textit{Confuzzer} design uses the Intel PIN Dynamic
Binary Instrumentation (DBI) tool to do Taint Analysis and then uses z3 and the
Python z3 bindings to actually solve the constraints for the various inputs to
explore different paths in the binary. In order to run the system at a
reasonable speed, and take advantage of the parallelizability of the system, we
also need to distribute the taint analysis over multiple machines. While the
final design of the system was fairly straightforward, I had a lot of issues in
implementing the Intel PIN tool since we didn't have a good Intermediate
Representation so we had to handle each individual assembly instruction
manually, which resulted in a lot of bugs during the implementation. PIN also
didn't have the cleanest memory and API model, resulting in many memory issues
while trying to implement the system. In order to avoid these problems in future
systems, while still maintaining our goals of closed-source fuzzing, using an
alternative DBI or even moving to a emulator such as the User-Mode Emulation
might result in an easier implementation.

When testing our implementation compared with other similar systems, we found
that the versus other similar systems, execution of the binary was significantly
slower than the other fuzzers we had, running at about 3 executions per second
on our test cases, versus about 10k executions per second using some of the high
end fuzzers we were testing. However our evaluations also shows how we have
orders of magnitude fewer test cases that we need to run in order to fully
explore the test cases. Overall, from these test cases we see that while the
executions are factors slower, the speed-up from the smaller set of test cases
needed greatly counteracts these issues, and as a result this fuzzer succeeds at
the class of programs we are trying to analyze with this system.

In Chapter 2, we'll give an overview of existing systems in the space, as well
as the similarities and differences with the \textit{Confuzzer} system. Next in
Chapter 3, we'll talk about the design of the Taint Analysis and Concolic
Execution system. Chapter 4 talks about our actual implementation of the system
and some of the issues we've had during implementation. Then Chapter 5 will be
our evaluation of the system and its performance on some test programs. Chapter
6 will be about future work and improvements that can be made to the
system. Finally, Chapter 7 concludes the discussion on our system. We also
include an appendix showing the execution of \textit{Confuzzer} on one of our
larger test cases.
